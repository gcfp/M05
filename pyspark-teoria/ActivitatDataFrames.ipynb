{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activitat DataFrames PySpark a partir dels  datasets:  flights,  planes i airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[1;32m----> 2\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mgetOrCreate()\n\u001b[0;32m      3\u001b[0m flights_small_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mcsv(\u001b[39m\"\u001b[39m\u001b[39mflights_small.csv\u001b[39m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m flights_small_df \u001b[39m=\u001b[39m flights_small_df\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39myear\u001b[39m\u001b[39m\"\u001b[39m, flights_small_df[\u001b[39m\"\u001b[39m\u001b[39myear\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39minteger\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Informatica\\anaconda3\\envs\\entornVirtual\\lib\\site-packages\\pyspark\\sql\\session.py:228\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         sparkConf\u001b[39m.\u001b[39mset(key, value)\n\u001b[0;32m    227\u001b[0m     \u001b[39m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate(sparkConf)\n\u001b[0;32m    229\u001b[0m \u001b[39m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m# by all sessions.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m session \u001b[39m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[1;32mc:\\Users\\Informatica\\anaconda3\\envs\\entornVirtual\\lib\\site-packages\\pyspark\\context.py:392\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[0;32m    393\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32mc:\\Users\\Informatica\\anaconda3\\envs\\entornVirtual\\lib\\site-packages\\pyspark\\context.py:144\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    141\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 144\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0;32m    147\u001b[0m                   conf, jsc, profiler_cls)\n",
      "File \u001b[1;32mc:\\Users\\Informatica\\anaconda3\\envs\\entornVirtual\\lib\\site-packages\\pyspark\\context.py:339\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[1;32m--> 339\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    340\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[0;32m    342\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[1;32mc:\\Users\\Informatica\\anaconda3\\envs\\entornVirtual\\lib\\site-packages\\pyspark\\java_gateway.py:108\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.1\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(conn_info_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m info:\n\u001b[0;32m    111\u001b[0m     gateway_port \u001b[39m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "flights_small_df = spark.read.csv(\"flights_small.csv\", header=True)\n",
    "flights_small_df = flights_small_df.withColumn(\"year\", flights_small_df[\"year\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"month\", flights_small_df[\"month\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"day\", flights_small_df[\"day\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"dep_time\", flights_small_df[\"dep_time\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"dep_delay\", flights_small_df[\"dep_delay\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"arr_time\", flights_small_df[\"arr_time\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"arr_delay\", flights_small_df[\"arr_delay\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"flight\", flights_small_df[\"flight\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"air_time\", flights_small_df[\"air_time\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"distance\", flights_small_df[\"distance\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"hour\", flights_small_df[\"hour\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumn(\"minute\", flights_small_df[\"minute\"].cast(\"integer\"))\n",
    "flights_small_df = flights_small_df.withColumnRenamed(\"year\", \"flight_year\")\n",
    "flights_small_df.createOrReplaceTempView(\"flights_small_df\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudi de la Petjada de Carboni en funció del temps a l’aire (Petjada de Carboni=airtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#1. Quin és l’avió («tailnum») amb major petjada de carboni.\n",
    "query = 'SELECT tailnum, SUM(air_time) AS air_time FROM flights_small_df GROUP BY tailnum ORDER BY air_time DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#2. Quin és l’avió («tailnum») amb menor petjada de carboni. ¿ha estat temps sense volar?\n",
    "query = 'SELECT tailnum, SUM(air_time) AS air_time FROM flights_small_df WHERE air_time IS NOT NULL GROUP BY tailnum ORDER BY air_time ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#3. Quina és la petjada promig i la petjada mitjana segons «tailnum». Si hi aprecieu diferència notable a què ho atribuiu?\n",
    "query = 'SELECT tailnum, ROUND(AVG(air_time), 2) AS air_time_avg, ROUND(MEAN(air_time), 2) AS air_time_mean FROM flights_small_df GROUP BY tailnum'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#4. Quina és l’aerolinia amb major petjada de carboni.\n",
    "query = 'SELECT carrier, SUM(air_time) AS air_time FROM flights_small_df GROUP BY carrier ORDER BY air_time DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#5. Quina és l’aerolinia amb menor petjada de carboni.\n",
    "query = 'SELECT carrier, SUM(air_time) AS air_time FROM flights_small_df GROUP BY carrier ORDER BY air_time ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#6. Quin és el fabricant d’avions amb major petjada de carboni.\n",
    "planes_df = spark.read.csv(\"planes.csv\", header=True)\n",
    "planes_df = planes_df.withColumn(\"year\", planes_df[\"year\"].cast(\"integer\"))\n",
    "planes_df = planes_df.withColumn(\"engines\", planes_df[\"engines\"].cast(\"integer\"))\n",
    "planes_df = planes_df.withColumn(\"seats\", planes_df[\"seats\"].cast(\"integer\"))\n",
    "planes_df = planes_df.withColumn(\"speed\", planes_df[\"speed\"].cast(\"integer\"))\n",
    "flights_planes_df = flights_small_df.join(planes_df, flights_small_df.tailnum == planes_df.tailnum, 'inner')\n",
    "flights_planes_df.createOrReplaceTempView(\"flights_planes_df\")\n",
    "query = 'SELECT manufacturer, SUM(air_time) AS air_time FROM flights_planes_df GROUP BY manufacturer ORDER BY air_time DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#7. Quin és el fabricants d’avions amb menor petjada de carboni.\n",
    "query = 'SELECT manufacturer, SUM(air_time) AS air_time FROM flights_planes_df GROUP BY manufacturer ORDER BY air_time ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#8. Quin és el model d’avions amb major petjada de carboni.\n",
    "query = 'SELECT manufacturer, model, SUM(air_time) AS air_time FROM flights_planes_df GROUP BY manufacturer, model ORDER BY air_time DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#9. Quin és el model d’avions amb menor petjada de carboni.\n",
    "query = 'SELECT manufacturer, model, SUM(air_time) AS air_time FROM flights_planes_df GROUP BY manufacturer, model ORDER BY air_time ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#10. Fes una taula de petjada de carboni en funció dels anys de fabricació dels avions\n",
    "query = 'SELECT year, SUM(air_time) AS air_time FROM flights_planes_df GROUP BY year ORDER BY year'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#11. Quina és l’aerolinia amb major petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT carrier, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY carrier ORDER BY air_time_per_seat DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#12. Quina és l’aerolinia amb menor petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT carrier, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY carrier ORDER BY air_time_per_seat ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#13. Quin és el fabricant d’avions amb major petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT manufacturer, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY manufacturer ORDER BY air_time_per_seat DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#14. Quin és el fabricants d’avions amb menor petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT manufacturer, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY manufacturer ORDER BY air_time_per_seat ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#15. Quin és el model d’avions amb major petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT manufacturer, model, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY manufacturer, model ORDER BY air_time_per_seat DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#16. Quin és el model d’avions amb menor petjada de carboni normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT manufacturer, model, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY manufacturer, model ORDER BY air_time_per_seat ASC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#17. Fes una taula de petjada de carboni en funció dels anys de fabricació dels avions normalitzat al número de seients disponible a cada vol.\n",
    "query = 'SELECT year, SUM(air_time) / SUM(seats) AS air_time_per_seat FROM flights_planes_df GROUP BY year ORDER BY year'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#19. Surt a compte des del punt de vista de la petjada de cada passatger que els avions tinguin més seients, menys o no és una hipòtesi vàlida?\n",
    "query = 'SELECT seats, air_time FROM flights_planes_df'\n",
    "spark.sql(query).show()\n",
    "print(\"No es una hipòtesi vàlida, ja que hi ha avions amb molts seients i petjada de carboni baixa i avions amb pocs seients i petjada de carboni alta.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudi de la Puntualitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#1. Quina és l’aerolinia amb més retard?\n",
    "query = 'SELECT carrier, SUM(arr_delay) AS arr_delay FROM flights_small_df GROUP BY carrier ORDER BY arr_delay DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'entornVirtual' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n entornVirtual ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#2. Quina és l’aerolinia amb més retard normalitzat al número de vols operats?\n",
    "query = 'SELECT carrier, SUM(arr_delay) / COUNT(arr_delay) AS arr_delay_per_flight FROM flights_small_df GROUP BY carrier ORDER BY arr_delay_per_flight DESC LIMIT 1'\n",
    "spark.sql(query).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a450dc57107488e8056d0210785f00d7f06571c485be8ba3ab641e7ac7dde7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
